{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\n\nimport PIL.Image as Image\nimport pathlib\nimport os\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\n\nfrom tensorflow import keras\nfrom keras.preprocessing import image\nfrom tensorflow.keras.utils import img_to_array\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-09-24T12:21:22.940439Z","iopub.execute_input":"2022-09-24T12:21:22.940781Z","iopub.status.idle":"2022-09-24T12:21:29.530842Z","shell.execute_reply.started":"2022-09-24T12:21:22.940704Z","shell.execute_reply":"2022-09-24T12:21:29.529848Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Get directory path to Training dataset\ntrain_dir = pathlib.Path('../input/gender-recognition-dataset/Gender Recognition Dataset/Training')\n# Get a list of all images in the Training dataset\ntrain_image_paths = list(train_dir.glob(r'**/*.jpg'))\n\n# Get directory path to Validation dataset\nvalid_dir = pathlib.Path('../input/gender-recognition-dataset/Gender Recognition Dataset/Validation')\n# Get a list of all images in the Validation dataset\nvalid_image_paths = list(valid_dir.glob(r'**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:21:31.938849Z","iopub.execute_input":"2022-09-24T12:21:31.940209Z","iopub.status.idle":"2022-09-24T12:23:10.028588Z","shell.execute_reply.started":"2022-09-24T12:21:31.940160Z","shell.execute_reply":"2022-09-24T12:23:10.027509Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Image Processing","metadata":{}},{"cell_type":"code","source":"# Create a function to extract the labels from image filepath\ndef image_processing(filepath):\n    labels = [str(filepath[i]).split('/')[-2]\n             for i in range(len(filepath))]\n    \n    # Create a DataFrame and input the filepath and labels\n    filepath = pd.Series(filepath, name = 'Filepath').astype(str)\n    labels = pd.Series(labels, name = 'Label')\n    \n    df = pd.concat([filepath, labels], axis='columns')\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:10.031407Z","iopub.execute_input":"2022-09-24T12:23:10.032050Z","iopub.status.idle":"2022-09-24T12:23:10.038349Z","shell.execute_reply.started":"2022-09-24T12:23:10.032011Z","shell.execute_reply":"2022-09-24T12:23:10.037426Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Create a train and validation DataFrame\ntrain_df = image_processing(train_image_paths)\nval_df = image_processing(valid_image_paths)","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:10.040144Z","iopub.execute_input":"2022-09-24T12:23:10.043052Z","iopub.status.idle":"2022-09-24T12:23:10.235692Z","shell.execute_reply.started":"2022-09-24T12:23:10.043023Z","shell.execute_reply":"2022-09-24T12:23:10.234724Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create DataFrame with just one label for each label\ndf_unique = train_df.copy().drop_duplicates(subset=['Label']).reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:10.238342Z","iopub.execute_input":"2022-09-24T12:23:10.238754Z","iopub.status.idle":"2022-09-24T12:23:10.260191Z","shell.execute_reply.started":"2022-09-24T12:23:10.238717Z","shell.execute_reply":"2022-09-24T12:23:10.259292Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Generate new images from dataset\ntrain_generator = tf.keras.preprocessing.image.ImageDataGenerator(\npreprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input\n)\n\nval_generator = tf.keras.preprocessing.image.ImageDataGenerator(\npreprocessing_function = tf.keras.applications.mobilenet_v2.preprocess_input\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:10.261573Z","iopub.execute_input":"2022-09-24T12:23:10.261922Z","iopub.status.idle":"2022-09-24T12:23:10.269420Z","shell.execute_reply.started":"2022-09-24T12:23:10.261888Z","shell.execute_reply":"2022-09-24T12:23:10.267810Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Generate images using 'train_df' DataFrame\ntrain_images = train_generator.flow_from_dataframe(\n    dataframe  = train_df,\n    x_col = 'Filepath',\n    y_col = 'Label',\n    target_size = (224, 224),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    batch_size = 32,\n    shuffle = True,\n    seed = 0,\n    rotation_range = 30,\n    zoom_range = 0.15,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.15,\n    horizontal_flip = True,\n    fill_mode = 'nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:10.271442Z","iopub.execute_input":"2022-09-24T12:23:10.271726Z","iopub.status.idle":"2022-09-24T12:23:30.529367Z","shell.execute_reply.started":"2022-09-24T12:23:10.271701Z","shell.execute_reply":"2022-09-24T12:23:30.528255Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Found 47406 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate images using 'val_df' DataFrame\nval_images = train_generator.flow_from_dataframe(\n    dataframe  = val_df,\n    x_col = 'Filepath',\n    y_col = 'Label',\n    target_size = (224, 224),\n    color_mode = 'rgb',\n    class_mode = 'categorical',\n    batch_size = 32,\n    shuffle = True,\n    seed = 0,\n    rotation_range = 30,\n    zoom_range = 0.15,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    shear_range = 0.15,\n    horizontal_flip = True,\n    fill_mode = 'nearest'\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:30.531882Z","iopub.execute_input":"2022-09-24T12:23:30.532512Z","iopub.status.idle":"2022-09-24T12:23:35.914616Z","shell.execute_reply.started":"2022-09-24T12:23:30.532474Z","shell.execute_reply":"2022-09-24T12:23:35.913439Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 11831 validated image filenames belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use Tensorflow pretrained model\npretrained_model = tf.keras.applications.MobileNetV2(\ninput_shape= (224, 224, 3),\ninclude_top = False,\nweights = 'imagenet',\npooling = 'avg'\n)\n\n# Freeze weights\npretrained_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:35.916375Z","iopub.execute_input":"2022-09-24T12:23:35.916769Z","iopub.status.idle":"2022-09-24T12:23:39.938212Z","shell.execute_reply.started":"2022-09-24T12:23:35.916728Z","shell.execute_reply":"2022-09-24T12:23:39.937234Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"2022-09-24 12:23:36.030001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:36.126352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:36.127150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:36.128731: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-09-24 12:23:36.129059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:36.129718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:36.130376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:38.375652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:38.376536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:38.377234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-09-24 12:23:38.377858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n9412608/9406464 [==============================] - 0s 0us/step\n9420800/9406464 [==============================] - 0s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create weights\ninputs = pretrained_model.input\n\nx = tf.keras.layers.Dense(128, activation = 'relu')(pretrained_model.output)\nx = tf.keras.layers.Dense(128, activation = 'relu')(x)\n\noutputs = tf.keras.layers.Dense(2, activation = 'softmax')(x)\n\nmodel = tf.keras.Model(inputs = inputs, outputs = outputs)\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'categorical_crossentropy',\n    metrics = ['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:39.939561Z","iopub.execute_input":"2022-09-24T12:23:39.940268Z","iopub.status.idle":"2022-09-24T12:23:40.009573Z","shell.execute_reply.started":"2022-09-24T12:23:39.940228Z","shell.execute_reply":"2022-09-24T12:23:40.008277Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Train model\nhistory = model.fit(\n    train_images,\n    validation_data = val_images,\n    batch_size = 32,\n    epochs = 20,\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor = 'val_loss',\n            patience = 2,\n            restore_best_weights = True\n        )  \n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:23:40.012350Z","iopub.execute_input":"2022-09-24T12:23:40.013057Z","iopub.status.idle":"2022-09-24T12:42:13.952690Z","shell.execute_reply.started":"2022-09-24T12:23:40.013019Z","shell.execute_reply":"2022-09-24T12:42:13.951612Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2022-09-24 12:23:40.291306: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2022-09-24 12:23:43.832430: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","output_type":"stream"},{"name":"stdout","text":"1482/1482 [==============================] - 341s 224ms/step - loss: 0.2887 - accuracy: 0.8812 - val_loss: 0.2348 - val_accuracy: 0.9059\nEpoch 2/20\n1482/1482 [==============================] - 129s 87ms/step - loss: 0.2310 - accuracy: 0.9065 - val_loss: 0.2195 - val_accuracy: 0.9162\nEpoch 3/20\n1482/1482 [==============================] - 124s 83ms/step - loss: 0.2113 - accuracy: 0.9171 - val_loss: 0.2063 - val_accuracy: 0.9173\nEpoch 4/20\n1482/1482 [==============================] - 125s 84ms/step - loss: 0.1989 - accuracy: 0.9205 - val_loss: 0.2007 - val_accuracy: 0.9178\nEpoch 5/20\n1482/1482 [==============================] - 123s 83ms/step - loss: 0.1888 - accuracy: 0.9249 - val_loss: 0.1926 - val_accuracy: 0.9236\nEpoch 6/20\n1482/1482 [==============================] - 127s 86ms/step - loss: 0.1795 - accuracy: 0.9308 - val_loss: 0.1940 - val_accuracy: 0.9259\nEpoch 7/20\n1482/1482 [==============================] - 128s 86ms/step - loss: 0.1683 - accuracy: 0.9348 - val_loss: 0.2031 - val_accuracy: 0.9184\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create labels dictionary\nlabels = {0: 'female',\n         1: 'male'}","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:44:20.832035Z","iopub.execute_input":"2022-09-24T12:44:20.832699Z","iopub.status.idle":"2022-09-24T12:44:20.843540Z","shell.execute_reply.started":"2022-09-24T12:44:20.832649Z","shell.execute_reply":"2022-09-24T12:44:20.842546Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Create a function for image processing and prediction\ndef output(imagepath):\n    img = image.load_img(imagepath, target_size=(224, 224, 3))\n    img = img_to_array(img)\n    img = img/255\n    img = np.expand_dims(img, [0])\n    \n    prediction = model.predict(img)[0]\n    \n    idx = prediction.argmax()\n    prediction_label = labels[idx]\n    \n    return prediction_label","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:44:52.081186Z","iopub.execute_input":"2022-09-24T12:44:52.081561Z","iopub.status.idle":"2022-09-24T12:44:52.088170Z","shell.execute_reply.started":"2022-09-24T12:44:52.081528Z","shell.execute_reply":"2022-09-24T12:44:52.087041Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Predict gender\nimg = output('../input/gender-classification-dataset/Validation/female/112953.jpg.jpg')\nimg","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:44:53.360547Z","iopub.execute_input":"2022-09-24T12:44:53.360951Z","iopub.status.idle":"2022-09-24T12:44:53.417702Z","shell.execute_reply.started":"2022-09-24T12:44:53.360916Z","shell.execute_reply":"2022-09-24T12:44:53.416828Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'female'"},"metadata":{}}]},{"cell_type":"code","source":"# Save model\nmodel.save('GR.h5')","metadata":{"execution":{"iopub.status.busy":"2022-09-24T12:44:58.831598Z","iopub.execute_input":"2022-09-24T12:44:58.831997Z","iopub.status.idle":"2022-09-24T12:44:59.118761Z","shell.execute_reply.started":"2022-09-24T12:44:58.831962Z","shell.execute_reply":"2022-09-24T12:44:59.117726Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n  category=CustomMaskWarning)\n","output_type":"stream"}]}]}